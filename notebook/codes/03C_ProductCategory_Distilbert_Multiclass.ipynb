{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multiclass_classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "# Importing the libraries needed\n",
    "import pandas as pd\n",
    "import torch\n",
    "import transformers\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import DistilBertModel, DistilBertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the device for GPU usage\n",
    "\n",
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## formating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_cat(string, ref):\n",
    "     return ref.index(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data from csv\n",
    "df = pd.read_csv('../datasets/cleaned/combined_text.csv')\n",
    "\n",
    "# drop duplicates\n",
    "df.drop_duplicates(subset=['combined_text'], keep='first', ignore_index=True, inplace=True)\n",
    "\n",
    "# encode category\n",
    "category_list = list(df.category.unique())\n",
    "df['label'] = df['category'].map(lambda x: encode_cat(x, category_list))\n",
    "\n",
    "df.drop(columns=['asin'], inplace=True)\n",
    "df.rename(columns={'combined_text': 'text'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have a 9 year old Badger 1 that needs replac...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>model number This may help InSinkErator Model ...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text    category  label\n",
       "0  I have a 9 year old Badger 1 that needs replac...  appliances      0\n",
       "1  model number This may help InSinkErator Model ...  appliances      0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing dataset and dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some key variables that will be used later on in the training\n",
    "MAX_LEN = 512\n",
    "TRAIN_BATCH_SIZE = 4\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 1\n",
    "LEARNING_RATE = 1e-05\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Triage(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = str(self.data.text[index])\n",
    "        text = \" \".join(text.split())\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs['input_ids']\n",
    "        mask = inputs['attention_mask']\n",
    "\n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "            'targets': torch.tensor(self.data.label[index], dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (1271009, 3)\n",
      "TRAIN Dataset: (1143908, 3)\n",
      "TEST Dataset: (127101, 3)\n"
     ]
    }
   ],
   "source": [
    "# Creating the dataset and dataloader for the neural network\n",
    "\n",
    "train_size = 0.9\n",
    "train_dataset=df.sample(frac=train_size,random_state=200)\n",
    "test_dataset=df.drop(train_dataset.index).reset_index(drop=True)\n",
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_dataset.shape))\n",
    "\n",
    "training_set = Triage(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = Triage(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does this have a 240V Twist-lock socket? It lo...</td>\n",
       "      <td>patio_lawn_and_garden</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i don't see a plug underneath the unit where t...</td>\n",
       "      <td>home_and_kitchen</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Will these fit an Artic Cat Wilcat 2014 as lon...</td>\n",
       "      <td>automotive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I will have no problem when I get the phone tu...</td>\n",
       "      <td>cell_phones_and_accessories</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jWhat is the size of each stamp? I need someth...</td>\n",
       "      <td>arts_crafts_and_sewing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143903</th>\n",
       "      <td>On this product description, it doesn't say if...</td>\n",
       "      <td>beauty</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143904</th>\n",
       "      <td>What are the actual measurements of this item?...</td>\n",
       "      <td>tools_and_home_improvement</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143905</th>\n",
       "      <td>can i use this in my 2014 Forrester (non turbo...</td>\n",
       "      <td>automotive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143906</th>\n",
       "      <td>DRM? Hi, Does anyone know what DRM this compil...</td>\n",
       "      <td>video_games</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143907</th>\n",
       "      <td>What do you use it for? Serf the Web, Check em...</td>\n",
       "      <td>electronics</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1143908 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  \\\n",
       "0        Does this have a 240V Twist-lock socket? It lo...   \n",
       "1        i don't see a plug underneath the unit where t...   \n",
       "2        Will these fit an Artic Cat Wilcat 2014 as lon...   \n",
       "3        I will have no problem when I get the phone tu...   \n",
       "4        jWhat is the size of each stamp? I need someth...   \n",
       "...                                                    ...   \n",
       "1143903  On this product description, it doesn't say if...   \n",
       "1143904  What are the actual measurements of this item?...   \n",
       "1143905  can i use this in my 2014 Forrester (non turbo...   \n",
       "1143906  DRM? Hi, Does anyone know what DRM this compil...   \n",
       "1143907  What do you use it for? Serf the Web, Check em...   \n",
       "\n",
       "                            category  label  \n",
       "0              patio_lawn_and_garden     14  \n",
       "1                   home_and_kitchen     10  \n",
       "2                         automotive      2  \n",
       "3        cell_phones_and_accessories      5  \n",
       "4             arts_crafts_and_sewing      1  \n",
       "...                              ...    ...  \n",
       "1143903                       beauty      4  \n",
       "1143904   tools_and_home_improvement     18  \n",
       "1143905                   automotive      2  \n",
       "1143906                  video_games     20  \n",
       "1143907                  electronics      7  \n",
       "\n",
       "[1143908 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>can I replace Badger 1 1/3 with a Badger 5 1/2...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can someone tell me if this Badger 5 disposer ...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>My present disposal has a 3 bolt connection. W...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>can you bake corn bread on this without it bur...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I need a device to let my dryer vent out, I li...</td>\n",
       "      <td>appliances</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127096</th>\n",
       "      <td>How do I get this to work for two players on p...</td>\n",
       "      <td>video_games</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127097</th>\n",
       "      <td>how many gig on the hard drive It is a 500gb h...</td>\n",
       "      <td>video_games</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127098</th>\n",
       "      <td>Does the kinect-less version still play blu ra...</td>\n",
       "      <td>video_games</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127099</th>\n",
       "      <td>Are there offline options for the games for Xb...</td>\n",
       "      <td>video_games</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127100</th>\n",
       "      <td>Does need to have kinect to play games? Most g...</td>\n",
       "      <td>video_games</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127101 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text     category  label\n",
       "0       can I replace Badger 1 1/3 with a Badger 5 1/2...   appliances      0\n",
       "1       Can someone tell me if this Badger 5 disposer ...   appliances      0\n",
       "2       My present disposal has a 3 bolt connection. W...   appliances      0\n",
       "3       can you bake corn bread on this without it bur...   appliances      0\n",
       "4       I need a device to let my dryer vent out, I li...   appliances      0\n",
       "...                                                   ...          ...    ...\n",
       "127096  How do I get this to work for two players on p...  video_games     20\n",
       "127097  how many gig on the hard drive It is a 500gb h...  video_games     20\n",
       "127098  Does the kinect-less version still play blu ra...  video_games     20\n",
       "127099  Are there offline options for the games for Xb...  video_games     20\n",
       "127100  Does need to have kinect to play games? Most g...  video_games     20\n",
       "\n",
       "[127101 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Neural Network for Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the customized model, \n",
    "# by adding a drop out and a dense layer on top of distil bert \n",
    "# to get the final output for the model. \n",
    "\n",
    "class DistillBERTClass(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DistillBERTClass, self).__init__()\n",
    "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
    "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
    "        self.dropout = torch.nn.Dropout(0.3)\n",
    "#         self.classifier = torch.nn.Linear(768, 4)\n",
    "        self.classifier = torch.nn.Linear(768, 21)\n",
    "#         self.classifier = torch.nn.Linear(768, 20)\n",
    "    \n",
    "        \n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        hidden_state = output_1[0]\n",
    "        pooler = hidden_state[:, 0]\n",
    "        pooler = self.pre_classifier(pooler)\n",
    "        pooler = torch.nn.ReLU()(pooler)\n",
    "        pooler = self.dropout(pooler)\n",
    "        output = self.classifier(pooler)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistillBERTClass(\n",
       "  (l1): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=21, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DistillBERTClass()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the loss function and optimizer\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calcuate the accuracy of the model\n",
    "\n",
    "def calcuate_accu(big_idx, targets):\n",
    "    n_correct = (big_idx==targets).sum().item()\n",
    "    return n_correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
    "\n",
    "def train(epoch, loader = training_loader):\n",
    "    tr_loss = 0\n",
    "    n_correct = 0\n",
    "    nb_tr_steps = 0\n",
    "    nb_tr_examples = 0\n",
    "    model.train()\n",
    "    for _,data in enumerate(training_loader, 0):\n",
    "        ids = data['ids'].to(device, dtype = torch.long)\n",
    "        mask = data['mask'].to(device, dtype = torch.long)\n",
    "        targets = data['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(ids, mask)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        tr_loss += loss.item()\n",
    "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "        n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples+=targets.size(0)\n",
    "        \n",
    "        if _%5000==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            accu_step = (n_correct*100)/nb_tr_examples \n",
    "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
    "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        # # When using GPU\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Training Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mriva\\.conda\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 2.9777770042419434\n",
      "Training Accuracy per 5000 steps: 25.0\n",
      "Training Loss per 5000 steps: 2.4404312234131296\n",
      "Training Accuracy per 5000 steps: 28.799240151969606\n",
      "Training Loss per 5000 steps: 2.314353849953764\n",
      "Training Accuracy per 5000 steps: 32.4042595740426\n",
      "Training Loss per 5000 steps: 2.220172642506239\n",
      "Training Accuracy per 5000 steps: 35.169322045196985\n",
      "Training Loss per 5000 steps: 2.134727981673331\n",
      "Training Accuracy per 5000 steps: 37.68811559422029\n",
      "Training Loss per 5000 steps: 2.0662048201359684\n",
      "Training Accuracy per 5000 steps: 39.72741090356386\n",
      "Training Loss per 5000 steps: 2.011505581018094\n",
      "Training Accuracy per 5000 steps: 41.392786907103094\n",
      "Training Loss per 5000 steps: 1.966009432741938\n",
      "Training Accuracy per 5000 steps: 42.70806548384332\n",
      "Training Loss per 5000 steps: 1.9250804053255879\n",
      "Training Accuracy per 5000 steps: 43.91077723056924\n",
      "Training Loss per 5000 steps: 1.8892987684284297\n",
      "Training Accuracy per 5000 steps: 44.92622386169196\n",
      "Training Loss per 5000 steps: 1.8574017720723404\n",
      "Training Accuracy per 5000 steps: 45.858082838343236\n",
      "Training Loss per 5000 steps: 1.829243028500643\n",
      "Training Accuracy per 5000 steps: 46.660515263358846\n",
      "Training Loss per 5000 steps: 1.8030775230898761\n",
      "Training Accuracy per 5000 steps: 47.41337644372594\n",
      "Training Loss per 5000 steps: 1.7780525487968137\n",
      "Training Accuracy per 5000 steps: 48.12656728358025\n",
      "Training Loss per 5000 steps: 1.7555786848461623\n",
      "Training Accuracy per 5000 steps: 48.73966086198769\n",
      "Training Loss per 5000 steps: 1.735165539068246\n",
      "Training Accuracy per 5000 steps: 49.328008959880535\n",
      "Training Loss per 5000 steps: 1.7170861519981546\n",
      "Training Accuracy per 5000 steps: 49.836564542943215\n",
      "Training Loss per 5000 steps: 1.7000979738182949\n",
      "Training Accuracy per 5000 steps: 50.31087869554476\n",
      "Training Loss per 5000 steps: 1.68475188936042\n",
      "Training Accuracy per 5000 steps: 50.733880734658506\n",
      "Training Loss per 5000 steps: 1.669600638692756\n",
      "Training Accuracy per 5000 steps: 51.137619604004165\n",
      "Training Loss per 5000 steps: 1.6554690747024878\n",
      "Training Accuracy per 5000 steps: 51.54823451765483\n",
      "Training Loss per 5000 steps: 1.6423055435366407\n",
      "Training Accuracy per 5000 steps: 51.90902943781488\n",
      "Training Loss per 5000 steps: 1.6303314125657027\n",
      "Training Accuracy per 5000 steps: 52.246570485722856\n",
      "Training Loss per 5000 steps: 1.6187080631473123\n",
      "Training Accuracy per 5000 steps: 52.57562977713237\n",
      "Training Loss per 5000 steps: 1.6080273886177587\n",
      "Training Accuracy per 5000 steps: 52.88018433179724\n",
      "Training Loss per 5000 steps: 1.5975691986012066\n",
      "Training Accuracy per 5000 steps: 53.17577459380325\n",
      "Training Loss per 5000 steps: 1.5872959366062356\n",
      "Training Accuracy per 5000 steps: 53.46881947061946\n",
      "Training Loss per 5000 steps: 1.5779579122582872\n",
      "Training Accuracy per 5000 steps: 53.73275012777683\n",
      "Training Loss per 5000 steps: 1.5686916626279965\n",
      "Training Accuracy per 5000 steps: 54.00407854229613\n",
      "Training Loss per 5000 steps: 1.5600372901005903\n",
      "Training Accuracy per 5000 steps: 54.24290177309122\n",
      "Training Loss per 5000 steps: 1.5519265886821472\n",
      "Training Accuracy per 5000 steps: 54.47130352464317\n",
      "Training Loss per 5000 steps: 1.5439170072914161\n",
      "Training Accuracy per 5000 steps: 54.7075502738692\n",
      "Training Loss per 5000 steps: 1.536380785932628\n",
      "Training Accuracy per 5000 steps: 54.92278173261417\n",
      "Training Loss per 5000 steps: 1.5288041108121786\n",
      "Training Accuracy per 5000 steps: 55.141938533705854\n",
      "Training Loss per 5000 steps: 1.5217501745408726\n",
      "Training Accuracy per 5000 steps: 55.340262704337036\n",
      "Training Loss per 5000 steps: 1.5149974826007213\n",
      "Training Accuracy per 5000 steps: 55.526539848343724\n",
      "Training Loss per 5000 steps: 1.5088566325395638\n",
      "Training Accuracy per 5000 steps: 55.70621829878723\n",
      "Training Loss per 5000 steps: 1.5026471983912444\n",
      "Training Accuracy per 5000 steps: 55.8730763617494\n",
      "Training Loss per 5000 steps: 1.4959201198949719\n",
      "Training Accuracy per 5000 steps: 56.06746806595755\n",
      "Training Loss per 5000 steps: 1.490494442882772\n",
      "Training Accuracy per 5000 steps: 56.21971169378619\n",
      "Training Loss per 5000 steps: 1.484538557662383\n",
      "Training Accuracy per 5000 steps: 56.38759306203469\n",
      "Training Loss per 5000 steps: 1.4785154165126104\n",
      "Training Accuracy per 5000 steps: 56.55191925893045\n",
      "Training Loss per 5000 steps: 1.4729756428609315\n",
      "Training Accuracy per 5000 steps: 56.7013966600159\n",
      "Training Loss per 5000 steps: 1.4676810526938435\n",
      "Training Accuracy per 5000 steps: 56.84915418998051\n",
      "Training Loss per 5000 steps: 1.462579074118046\n",
      "Training Accuracy per 5000 steps: 56.97815009931773\n",
      "Training Loss per 5000 steps: 1.4576408145828257\n",
      "Training Accuracy per 5000 steps: 57.111412838165165\n",
      "Training Loss per 5000 steps: 1.453079867769099\n",
      "Training Accuracy per 5000 steps: 57.231381602688685\n",
      "Training Loss per 5000 steps: 1.4483223669754697\n",
      "Training Accuracy per 5000 steps: 57.360075063510365\n",
      "Training Loss per 5000 steps: 1.4438834641863807\n",
      "Training Accuracy per 5000 steps: 57.483406319140336\n",
      "Training Loss per 5000 steps: 1.4395140871586254\n",
      "Training Accuracy per 5000 steps: 57.600173060518124\n",
      "Training Loss per 5000 steps: 1.4353935614410385\n",
      "Training Accuracy per 5000 steps: 57.707369170523314\n",
      "Training Loss per 5000 steps: 1.431301903814768\n",
      "Training Accuracy per 5000 steps: 57.819675216959936\n",
      "Training Loss per 5000 steps: 1.4271985696567602\n",
      "Training Accuracy per 5000 steps: 57.93314256483629\n",
      "Training Loss per 5000 steps: 1.4232966430051022\n",
      "Training Accuracy per 5000 steps: 58.04044135682507\n",
      "Training Loss per 5000 steps: 1.4194426616045732\n",
      "Training Accuracy per 5000 steps: 58.1548772041585\n",
      "Training Loss per 5000 steps: 1.4158071870900708\n",
      "Training Accuracy per 5000 steps: 58.24960636506776\n",
      "Training Loss per 5000 steps: 1.4123164882988462\n",
      "Training Accuracy per 5000 steps: 58.34720233142024\n",
      "Training Loss per 5000 steps: 1.4087181591166489\n",
      "Training Accuracy per 5000 steps: 58.446110715401\n",
      "The Total Accuracy for Epoch 0: 58.466502550904444\n",
      "Training Loss Epoch: 1.4079788790509382\n",
      "Training Accuracy Epoch: 58.466502550904444\n",
      "Wall time: 9h 43min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## validating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model, testing_loader):\n",
    "    tr_loss=0\n",
    "    nb_tr_steps=0\n",
    "    nb_tr_examples=0\n",
    "    \n",
    "    model.eval()\n",
    "    n_correct = 0; n_wrong = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for _, data in enumerate(testing_loader, 0):\n",
    "            ids = data['ids'].to(device, dtype = torch.long)\n",
    "            mask = data['mask'].to(device, dtype = torch.long)\n",
    "            targets = data['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "#             outputs = model(ids, mask).squeeze()\n",
    "            outputs = model(ids, mask)\n",
    "            \n",
    "            loss = loss_function(outputs, targets)\n",
    "            tr_loss += loss.item()\n",
    "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
    "            n_correct += calcuate_accu(big_idx, targets)\n",
    "\n",
    "            nb_tr_steps += 1\n",
    "            nb_tr_examples+=targets.size(0)\n",
    "            \n",
    "            if _%5000==0:\n",
    "                loss_step = tr_loss/nb_tr_steps\n",
    "                accu_step = (n_correct*100)/nb_tr_examples\n",
    "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
    "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
    "    epoch_loss = tr_loss/nb_tr_steps\n",
    "    epoch_accu = (n_correct*100)/nb_tr_examples\n",
    "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
    "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
    "    \n",
    "    return epoch_accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the validation section to print the accuracy and see how it performs\n",
      "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
      "Validation Loss per 100 steps: 0.9261605739593506\n",
      "Validation Accuracy per 100 steps: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mriva\\.conda\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss per 100 steps: 1.2189047949886223\n",
      "Validation Accuracy per 100 steps: 63.17736452709458\n",
      "Validation Loss per 100 steps: 1.1935676267591655\n",
      "Validation Accuracy per 100 steps: 63.918608139186084\n",
      "Validation Loss per 100 steps: 1.1847718260950362\n",
      "Validation Accuracy per 100 steps: 64.29571361909206\n",
      "Validation Loss per 100 steps: 1.1859883772218647\n",
      "Validation Accuracy per 100 steps: 64.36678166091696\n",
      "Validation Loss per 100 steps: 1.185738560735267\n",
      "Validation Accuracy per 100 steps: 64.37342506299748\n",
      "Validation Loss per 100 steps: 1.1825717648910097\n",
      "Validation Accuracy per 100 steps: 64.48285057164762\n",
      "Validation Loss per 100 steps: 1.179036021691308\n",
      "Validation Accuracy per 100 steps: 64.55958401188538\n",
      "Validation Loss per 100 steps: 1.1784293427084598\n",
      "Validation Accuracy per 100 steps: 64.5308867278318\n",
      "Validation Loss per 100 steps: 1.178874219909121\n",
      "Validation Accuracy per 100 steps: 64.60411990844648\n",
      "Validation Loss per 100 steps: 1.178964356685378\n",
      "Validation Accuracy per 100 steps: 64.59570808583828\n",
      "Validation Loss per 100 steps: 1.179927115219444\n",
      "Validation Accuracy per 100 steps: 64.557008054399\n",
      "Validation Loss per 100 steps: 1.1805781781775735\n",
      "Validation Accuracy per 100 steps: 64.58975683738605\n",
      "Validation Loss Epoch: 1.1793853412702804\n",
      "Validation Accuracy Epoch: 64.61475519468769\n",
      "Accuracy on test data = 64.61475519468769\n"
     ]
    }
   ],
   "source": [
    "print('This is the validation section to print the accuracy and see how it performs')\n",
    "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
    "\n",
    "acc = valid(model, testing_loader)\n",
    "print(f\"Accuracy on test data = {acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning with rest of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mriva\\.conda\\envs\\torch\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1944: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss per 5000 steps: 0.5841197371482849\n",
      "Training Accuracy per 5000 steps: 75.0\n",
      "Training Loss per 5000 steps: 1.1285755676335631\n",
      "Training Accuracy per 5000 steps: 65.74685062987403\n",
      "Training Loss per 5000 steps: 1.1267338031292955\n",
      "Training Accuracy per 5000 steps: 65.91090890910908\n",
      "Training Loss per 5000 steps: 1.135747613817797\n",
      "Training Accuracy per 5000 steps: 65.70728618092127\n",
      "Training Loss per 5000 steps: 1.1326839851631203\n",
      "Training Accuracy per 5000 steps: 65.88545572721364\n",
      "Training Loss per 5000 steps: 1.1298973110455015\n",
      "Training Accuracy per 5000 steps: 65.97736090556377\n",
      "Training Loss per 5000 steps: 1.1306134047355987\n",
      "Training Accuracy per 5000 steps: 65.98196726775774\n",
      "Training Loss per 5000 steps: 1.1323456350619614\n",
      "Training Accuracy per 5000 steps: 65.95097282934773\n",
      "Training Loss per 5000 steps: 1.1318313335023007\n",
      "Training Accuracy per 5000 steps: 65.9564760880978\n",
      "Training Loss per 5000 steps: 1.1322432220282772\n",
      "Training Accuracy per 5000 steps: 65.9657563165263\n",
      "Training Loss per 5000 steps: 1.1312336793037283\n",
      "Training Accuracy per 5000 steps: 65.95768084638307\n",
      "Training Loss per 5000 steps: 1.1307585958037836\n",
      "Training Accuracy per 5000 steps: 65.97652769949637\n",
      "Training Loss per 5000 steps: 1.131027385410297\n",
      "Training Accuracy per 5000 steps: 65.94015099748337\n",
      "Training Loss per 5000 steps: 1.1281132384714834\n",
      "Training Accuracy per 5000 steps: 66.00513838248642\n",
      "Training Loss per 5000 steps: 1.1269174650502733\n",
      "Training Accuracy per 5000 steps: 66.03048527878173\n",
      "Training Loss per 5000 steps: 1.1273719358484853\n",
      "Training Accuracy per 5000 steps: 66.02911961173851\n",
      "Training Loss per 5000 steps: 1.1273751999646013\n",
      "Training Accuracy per 5000 steps: 66.04042449469381\n",
      "Training Loss per 5000 steps: 1.1276789951518054\n",
      "Training Accuracy per 5000 steps: 66.0359878119081\n",
      "Training Loss per 5000 steps: 1.1272397246382508\n",
      "Training Accuracy per 5000 steps: 66.05676603593294\n",
      "Training Loss per 5000 steps: 1.1258122730099498\n",
      "Training Accuracy per 5000 steps: 66.09509373585541\n",
      "Training Loss per 5000 steps: 1.1256320468948113\n",
      "Training Accuracy per 5000 steps: 66.12408875911241\n",
      "Training Loss per 5000 steps: 1.1251443434594677\n",
      "Training Accuracy per 5000 steps: 66.14841763411778\n",
      "Training Loss per 5000 steps: 1.1241448921683588\n",
      "Training Accuracy per 5000 steps: 66.1975800219998\n",
      "Training Loss per 5000 steps: 1.1234722682371046\n",
      "Training Accuracy per 5000 steps: 66.22072851540422\n",
      "Training Loss per 5000 steps: 1.1229598158270515\n",
      "Training Accuracy per 5000 steps: 66.24298964175298\n",
      "Training Loss per 5000 steps: 1.1225085934569345\n",
      "Training Accuracy per 5000 steps: 66.25866993064055\n",
      "Training Loss per 5000 steps: 1.1222237649990505\n",
      "Training Accuracy per 5000 steps: 66.26525949800386\n",
      "Training Loss per 5000 steps: 1.1217316326478477\n",
      "Training Accuracy per 5000 steps: 66.2758053644047\n",
      "Training Loss per 5000 steps: 1.1213654515962956\n",
      "Training Accuracy per 5000 steps: 66.28684795108606\n",
      "Training Loss per 5000 steps: 1.1206925784190969\n",
      "Training Accuracy per 5000 steps: 66.32143916248853\n",
      "Training Loss per 5000 steps: 1.1202925197896758\n",
      "Training Accuracy per 5000 steps: 66.32855780961461\n",
      "Training Loss per 5000 steps: 1.1196846309739859\n",
      "Training Accuracy per 5000 steps: 66.3371526635312\n",
      "Training Loss per 5000 steps: 1.1191416466272963\n",
      "Training Accuracy per 5000 steps: 66.35052280923244\n",
      "Training Loss per 5000 steps: 1.1186875689522968\n",
      "Training Accuracy per 5000 steps: 66.3683856461476\n",
      "Training Loss per 5000 steps: 1.119245143360876\n",
      "Training Accuracy per 5000 steps: 66.35225675143087\n",
      "Training Loss per 5000 steps: 1.1188605718290103\n",
      "Training Accuracy per 5000 steps: 66.36747790012629\n",
      "Training Loss per 5000 steps: 1.1185628412823532\n",
      "Training Accuracy per 5000 steps: 66.38199232226488\n",
      "Training Loss per 5000 steps: 1.118030153578397\n",
      "Training Accuracy per 5000 steps: 66.38639791136264\n",
      "Training Loss per 5000 steps: 1.1178915400193945\n",
      "Training Accuracy per 5000 steps: 66.3932031936674\n",
      "Training Loss per 5000 steps: 1.117755906526363\n",
      "Training Accuracy per 5000 steps: 66.40235178281137\n",
      "Training Loss per 5000 steps: 1.117282759100554\n",
      "Training Accuracy per 5000 steps: 66.41541792291038\n",
      "Training Loss per 5000 steps: 1.1168907770875014\n",
      "Training Accuracy per 5000 steps: 66.43211496529285\n",
      "Training Loss per 5000 steps: 1.1162770108311495\n",
      "Training Accuracy per 5000 steps: 66.45135023166556\n",
      "Training Loss per 5000 steps: 1.115870196676998\n",
      "Training Accuracy per 5000 steps: 66.45527230105907\n",
      "Training Loss per 5000 steps: 1.115189271756631\n",
      "Training Accuracy per 5000 steps: 66.47344784796432\n",
      "Training Loss per 5000 steps: 1.1148588236076933\n",
      "Training Accuracy per 5000 steps: 66.47648232674521\n",
      "Training Loss per 5000 steps: 1.1148028812399495\n",
      "Training Accuracy per 5000 steps: 66.47655879757045\n",
      "Training Loss per 5000 steps: 1.114404699607753\n",
      "Training Accuracy per 5000 steps: 66.4828022008417\n",
      "Training Loss per 5000 steps: 1.1138414391418667\n",
      "Training Accuracy per 5000 steps: 66.49982708405382\n",
      "Training Loss per 5000 steps: 1.1130315519825658\n",
      "Training Accuracy per 5000 steps: 66.52789172289093\n",
      "Training Loss per 5000 steps: 1.112740270846337\n",
      "Training Accuracy per 5000 steps: 66.53223387106452\n",
      "Training Loss per 5000 steps: 1.11220246638995\n",
      "Training Accuracy per 5000 steps: 66.54611158387614\n",
      "Training Loss per 5000 steps: 1.111864671349066\n",
      "Training Accuracy per 5000 steps: 66.55830169883961\n",
      "Training Loss per 5000 steps: 1.111710803848367\n",
      "Training Accuracy per 5000 steps: 66.5621073128026\n",
      "Training Loss per 5000 steps: 1.111039040910962\n",
      "Training Accuracy per 5000 steps: 66.58604968129748\n",
      "Training Loss per 5000 steps: 1.1106533897616153\n",
      "Training Accuracy per 5000 steps: 66.6021214468311\n",
      "Training Loss per 5000 steps: 1.1103593622682983\n",
      "Training Accuracy per 5000 steps: 66.61449423394916\n",
      "Training Loss per 5000 steps: 1.1099147983450768\n",
      "Training Accuracy per 5000 steps: 66.62318728706215\n",
      "The Total Accuracy for Epoch 0: 66.62485094955188\n",
      "Training Loss Epoch: 1.1098565463725953\n",
      "Training Accuracy Epoch: 66.62485094955188\n",
      "Wall time: 9h 42min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(EPOCHS):\n",
    "    train(epoch, loader=testing_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the Trained Model Artifacts for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files saved\n"
     ]
    }
   ],
   "source": [
    "# Saving the files for re-use\n",
    "\n",
    "output_model_file = '../models/pytorch_distilbert_amazon2.bin'\n",
    "output_vocab_file = '../models/vocab_distilbert_amazon2.bin'\n",
    "\n",
    "model_to_save = model\n",
    "torch.save(model_to_save, output_model_file)\n",
    "tokenizer.save_vocabulary(output_vocab_file)\n",
    "\n",
    "print('All files saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
